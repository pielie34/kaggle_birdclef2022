{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65baf4ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:21:04.823273Z",
     "iopub.status.busy": "2022-05-22T16:21:04.821763Z",
     "iopub.status.idle": "2022-05-22T16:21:33.205196Z",
     "shell.execute_reply": "2022-05-22T16:21:33.204184Z",
     "shell.execute_reply.started": "2022-05-22T16:16:33.526730Z"
    },
    "papermill": {
     "duration": 28.404367,
     "end_time": "2022-05-22T16:21:33.205369",
     "exception": false,
     "start_time": "2022-05-22T16:21:04.801002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ../input/torchlibrosa/torchlibrosa-0.0.5-py3-none-any.whl > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8e3bcce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:21:33.248945Z",
     "iopub.status.busy": "2022-05-22T16:21:33.248188Z",
     "iopub.status.idle": "2022-05-22T16:21:39.781356Z",
     "shell.execute_reply": "2022-05-22T16:21:39.780432Z",
     "shell.execute_reply.started": "2022-05-22T16:17:02.206459Z"
    },
    "papermill": {
     "duration": 6.55713,
     "end_time": "2022-05-22T16:21:39.781511",
     "exception": false,
     "start_time": "2022-05-22T16:21:33.224381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import audioread\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as torchdata\n",
    "\n",
    "from contextlib import contextmanager\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from typing import Optional\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
    "\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "from torchlibrosa.stft import LogmelFilterBank, Spectrogram\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "from tqdm import tqdm\n",
    "\n",
    "import albumentations as A\n",
    "import albumentations.pytorch.transforms as T\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "422f5b01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:21:39.878661Z",
     "iopub.status.busy": "2022-05-22T16:21:39.877349Z",
     "iopub.status.idle": "2022-05-22T16:21:39.884697Z",
     "shell.execute_reply": "2022-05-22T16:21:39.884161Z",
     "shell.execute_reply.started": "2022-05-22T16:17:08.627987Z"
    },
    "papermill": {
     "duration": 0.085933,
     "end_time": "2022-05-22T16:21:39.884828",
     "exception": false,
     "start_time": "2022-05-22T16:21:39.798895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-22 16:21:39,876 - INFO - logger set up\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "    \n",
    "    \n",
    "def get_logger(out_file=None):\n",
    "    logger = logging.getLogger()\n",
    "    formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "    logger.handlers = []\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(formatter)\n",
    "    handler.setLevel(logging.INFO)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    if out_file is not None:\n",
    "        fh = logging.FileHandler(out_file)\n",
    "        fh.setFormatter(formatter)\n",
    "        fh.setLevel(logging.INFO)\n",
    "        logger.addHandler(fh)\n",
    "    logger.info(\"logger set up\")\n",
    "    return logger\n",
    "    \n",
    "    \n",
    "@contextmanager\n",
    "def timer(name: str, logger: Optional[logging.Logger] = None):\n",
    "    t0 = time.time()\n",
    "    msg = f\"[{name}] start\"\n",
    "    if logger is None:\n",
    "        print(msg)\n",
    "    else:\n",
    "        logger.info(msg)\n",
    "    yield\n",
    "\n",
    "    msg = f\"[{name}] done in {time.time() - t0:.2f} s\"\n",
    "    if logger is None:\n",
    "        print(msg)\n",
    "    else:\n",
    "        logger.info(msg)\n",
    "\n",
    "\n",
    "def get_device() -> torch.device:\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "device = get_device()\n",
    "logger = get_logger(\"main.log\")\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c25335b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:21:39.950708Z",
     "iopub.status.busy": "2022-05-22T16:21:39.949062Z",
     "iopub.status.idle": "2022-05-22T16:21:39.951297Z",
     "shell.execute_reply": "2022-05-22T16:21:39.951691Z",
     "shell.execute_reply.started": "2022-05-22T16:17:08.698488Z"
    },
    "papermill": {
     "duration": 0.049914,
     "end_time": "2022-05-22T16:21:39.951809",
     "exception": false,
     "start_time": "2022-05-22T16:21:39.901895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_layer(layer):\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    if hasattr(layer, \"bias\"):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "\n",
    "\n",
    "def init_bn(bn):\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.0)\n",
    "\n",
    "\n",
    "def init_weights(model):\n",
    "    classname = model.__class__.__name__\n",
    "    if classname.find(\"Conv2d\") != -1:\n",
    "        nn.init.xavier_uniform_(model.weight, gain=np.sqrt(2))\n",
    "        model.bias.data.fill_(0)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        model.weight.data.normal_(1.0, 0.02)\n",
    "        model.bias.data.fill_(0)\n",
    "    elif classname.find(\"GRU\") != -1:\n",
    "        for weight in model.parameters():\n",
    "            if len(weight.size()) > 1:\n",
    "                nn.init.orghogonal_(weight.data)\n",
    "    elif classname.find(\"Linear\") != -1:\n",
    "        model.weight.data.normal_(0, 0.01)\n",
    "        model.bias.data.zero_()\n",
    "\n",
    "\n",
    "def interpolate(x: torch.Tensor, ratio: int):\n",
    "    \"\"\"Interpolate data in time domain. This is used to compensate the\n",
    "    resolution reduction in downsampling of a CNN.\n",
    "    Args:\n",
    "      x: (batch_size, time_steps, classes_num)\n",
    "      ratio: int, ratio to interpolate\n",
    "    Returns:\n",
    "      upsampled: (batch_size, time_steps * ratio, classes_num)\n",
    "    \"\"\"\n",
    "    (batch_size, time_steps, classes_num) = x.shape\n",
    "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
    "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
    "    return upsampled\n",
    "\n",
    "\n",
    "def pad_framewise_output(framewise_output: torch.Tensor, frames_num: int):\n",
    "    \"\"\"Pad framewise_output to the same length as input frames. The pad value\n",
    "    is the same as the value of the last frame.\n",
    "    Args:\n",
    "      framewise_output: (batch_size, frames_num, classes_num)\n",
    "      frames_num: int, number of frames to pad\n",
    "    Outputs:\n",
    "      output: (batch_size, frames_num, classes_num)\n",
    "    \"\"\"\n",
    "    output = F.interpolate(\n",
    "        framewise_output.unsqueeze(1),\n",
    "        size=(frames_num, framewise_output.size(2)),\n",
    "        align_corners=True,\n",
    "        mode=\"bilinear\").squeeze(1)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "class AttBlockV2(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 out_features: int,\n",
    "                 activation=\"linear\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.att = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "        self.cla = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.att)\n",
    "        init_layer(self.cla)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (n_samples, n_in, n_time)\n",
    "        norm_att = torch.softmax(torch.tanh(self.att(x)), dim=-1)\n",
    "        cla = self.nonlinear_transform(self.cla(x))\n",
    "        x = torch.sum(norm_att * cla, dim=2)\n",
    "        return x, norm_att, cla\n",
    "\n",
    "    def nonlinear_transform(self, x):\n",
    "        if self.activation == 'linear':\n",
    "            return x\n",
    "        elif self.activation == 'sigmoid':\n",
    "            return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class TimmSED(nn.Module):\n",
    "    def __init__(self, base_model_name: str, pretrained=False, num_classes=24, in_channels=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.spec_augmenter = SpecAugmentation(time_drop_width=64//2, time_stripes_num=2,\n",
    "                                               freq_drop_width=8//2, freq_stripes_num=2)\n",
    "\n",
    "        self.bn0 = nn.BatchNorm2d(CFG.n_mels)\n",
    "\n",
    "        base_model = timm.create_model(\n",
    "            base_model_name, pretrained=pretrained, in_chans=in_channels)\n",
    "        layers = list(base_model.children())[:-2]\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "\n",
    "        if hasattr(base_model, \"fc\"):\n",
    "            in_features = base_model.fc.in_features\n",
    "        else:\n",
    "            in_features = base_model.classifier.in_features\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features, in_features, bias=True)\n",
    "        self.att_block = AttBlockV2(\n",
    "            in_features, num_classes, activation=\"sigmoid\")\n",
    "\n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_bn(self.bn0)\n",
    "        init_layer(self.fc1)\n",
    "        \n",
    "\n",
    "    def forward(self, input_data):\n",
    "        x = input_data # (batch_size, 3, time_steps, mel_bins)\n",
    "\n",
    "        frames_num = x.shape[2]\n",
    "\n",
    "        x = x.transpose(1, 3)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 3)\n",
    "\n",
    "        if self.training:\n",
    "            if random.random() < 0.25:\n",
    "                x = self.spec_augmenter(x)\n",
    "\n",
    "        x = x.transpose(2, 3)\n",
    "\n",
    "        x = self.encoder(x)\n",
    "        \n",
    "        # Aggregate in frequency axis\n",
    "        x = torch.mean(x, dim=3)\n",
    "\n",
    "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.relu_(self.fc1(x))\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "\n",
    "        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n",
    "        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n",
    "        segmentwise_logit = self.att_block.cla(x).transpose(1, 2)\n",
    "        segmentwise_output = segmentwise_output.transpose(1, 2)\n",
    "\n",
    "        interpolate_ratio = frames_num // segmentwise_output.size(1)\n",
    "\n",
    "        # Get framewise output\n",
    "        framewise_output = interpolate(segmentwise_output,\n",
    "                                       interpolate_ratio)\n",
    "        framewise_output = pad_framewise_output(framewise_output, frames_num)\n",
    "\n",
    "        framewise_logit = interpolate(segmentwise_logit, interpolate_ratio)\n",
    "        framewise_logit = pad_framewise_output(framewise_logit, frames_num)\n",
    "\n",
    "        output_dict = {\n",
    "            'framewise_output': framewise_output,\n",
    "            'clipwise_output': clipwise_output,\n",
    "            'logit': logit,\n",
    "            'framewise_logit': framewise_logit,\n",
    "        }\n",
    "\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "121cbaae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:21:39.991629Z",
     "iopub.status.busy": "2022-05-22T16:21:39.991029Z",
     "iopub.status.idle": "2022-05-22T16:21:39.996522Z",
     "shell.execute_reply": "2022-05-22T16:21:39.996113Z",
     "shell.execute_reply.started": "2022-05-22T16:17:08.732287Z"
    },
    "papermill": {
     "duration": 0.027526,
     "end_time": "2022-05-22T16:21:39.996625",
     "exception": false,
     "start_time": "2022-05-22T16:21:39.969099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/albumentations/augmentations/transforms.py:691: FutureWarning: This class has been deprecated. Please use CoarseDropout\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "mean = (0.485, 0.456, 0.406) # RGB\n",
    "std = (0.229, 0.224, 0.225) # RGB\n",
    "\n",
    "albu_transforms = {\n",
    "    'train' : A.Compose([\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.OneOf([\n",
    "                A.Cutout(max_h_size=5, max_w_size=16),\n",
    "                A.CoarseDropout(max_holes=4),\n",
    "            ], p=0.5),\n",
    "            A.Normalize(mean, std),\n",
    "    ]),\n",
    "    'valid' : A.Compose([\n",
    "            A.Normalize(mean, std),\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05307173",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:21:40.040388Z",
     "iopub.status.busy": "2022-05-22T16:21:40.039551Z",
     "iopub.status.idle": "2022-05-22T16:21:40.041310Z",
     "shell.execute_reply": "2022-05-22T16:21:40.041746Z",
     "shell.execute_reply.started": "2022-05-22T16:17:08.747371Z"
    },
    "papermill": {
     "duration": 0.028328,
     "end_time": "2022-05-22T16:21:40.041861",
     "exception": false,
     "start_time": "2022-05-22T16:21:40.013533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    EXP_ID = '018' \n",
    "\n",
    "    ######################\n",
    "    # Globals #\n",
    "    ######################\n",
    "    seed = 42\n",
    "    epochs = 5\n",
    "    train = True\n",
    "    folds = [0, 1, 2, 3, 4]\n",
    "    img_size = 224\n",
    "    main_metric = \"epoch_f1_at_03\"\n",
    "    minimize_metric = False\n",
    "\n",
    "    ######################\n",
    "    # Dataset #\n",
    "    ######################\n",
    "    transforms = {\n",
    "        \"train\": [{\"name\": \"Normalize\"}],\n",
    "        \"valid\": [{\"name\": \"Normalize\"}]\n",
    "    }\n",
    "    period = 5\n",
    "    n_mels = 224\n",
    "    fmin = 20\n",
    "    fmax = 16000\n",
    "    n_fft = 2048\n",
    "    hop_length = 512\n",
    "    sample_rate = 32000\n",
    "    melspectrogram_parameters = {\n",
    "        \"n_mels\": 224,\n",
    "        \"fmin\": 20,\n",
    "        \"fmax\": 16000\n",
    "    }\n",
    "\n",
    "    target_columns = 'afrsil1 akekee akepa1 akiapo akikik amewig aniani apapan arcter \\\n",
    "                      barpet bcnher belkin1 bkbplo bknsti bkwpet blkfra blknod bongul \\\n",
    "                      brant brnboo brnnod brnowl brtcur bubsan buffle bulpet burpar buwtea \\\n",
    "                      cacgoo1 calqua cangoo canvas caster1 categr chbsan chemun chukar cintea \\\n",
    "                      comgal1 commyn compea comsan comwax coopet crehon dunlin elepai ercfra eurwig \\\n",
    "                      fragul gadwal gamqua glwgul gnwtea golphe grbher3 grefri gresca gryfra gwfgoo \\\n",
    "                      hawama hawcoo hawcre hawgoo hawhaw hawpet1 hoomer houfin houspa hudgod iiwi incter1 \\\n",
    "                      jabwar japqua kalphe kauama laugul layalb lcspet leasan leater1 lessca lesyel lobdow lotjae \\\n",
    "                      madpet magpet1 mallar3 masboo mauala maupar merlin mitpar moudov norcar norhar2 normoc norpin \\\n",
    "                      norsho nutman oahama omao osprey pagplo palila parjae pecsan peflov perfal pibgre pomjae puaioh \\\n",
    "                      reccar redava redjun redpha1 refboo rempar rettro ribgul rinduc rinphe rocpig rorpar rudtur ruff \\\n",
    "                      saffin sander semplo sheowl shtsan skylar snogoo sooshe sooter1 sopsku1 sora spodov sposan \\\n",
    "                      towsol wantat1 warwhe1 wesmea wessan wetshe whfibi whiter whttro wiltur yebcar yefcan zebdov'.split()\n",
    "\n",
    "    ######################\n",
    "    # Loaders #\n",
    "    ######################\n",
    "    loader_params = {\n",
    "        \"train\": {\n",
    "            \"batch_size\": 16, \n",
    "            \"num_workers\": 0,\n",
    "            \"shuffle\": True\n",
    "        },\n",
    "        \"valid\": {\n",
    "            \"batch_size\": 32,\n",
    "            \"num_workers\": 0,\n",
    "            \"shuffle\": False\n",
    "        }\n",
    "    }\n",
    "\n",
    "    ######################\n",
    "    # Model #\n",
    "    ######################\n",
    "    base_model_name = \"tf_efficientnet_b0_ns\"\n",
    "    pooling = \"max\"\n",
    "    pretrained = False\n",
    "    num_classes = 152\n",
    "    in_channels = 3\n",
    "\n",
    "    N_FOLDS = 5\n",
    "    LR = 1e-3\n",
    "    T_max=10\n",
    "    min_lr=1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f48637f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:21:40.081955Z",
     "iopub.status.busy": "2022-05-22T16:21:40.081439Z",
     "iopub.status.idle": "2022-05-22T16:21:40.095504Z",
     "shell.execute_reply": "2022-05-22T16:21:40.095061Z",
     "shell.execute_reply.started": "2022-05-22T16:17:08.762148Z"
    },
    "papermill": {
     "duration": 0.03665,
     "end_time": "2022-05-22T16:21:40.095604",
     "exception": false,
     "start_time": "2022-05-22T16:21:40.058954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "AUDIO_PATH = '../input/birdclef-2022/train_audio'\n",
    "CLASSES = sorted(os.listdir(AUDIO_PATH))\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "class AudioParams:\n",
    "    \"\"\"\n",
    "    Parameters used for the audio data\n",
    "    \"\"\"\n",
    "    sr = 32000\n",
    "    duration = 5\n",
    "    # Melspectrogram\n",
    "    n_mels = 224\n",
    "    fmin = 20\n",
    "    fmax = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e21f768c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:21:40.138362Z",
     "iopub.status.busy": "2022-05-22T16:21:40.137672Z",
     "iopub.status.idle": "2022-05-22T16:21:40.139704Z",
     "shell.execute_reply": "2022-05-22T16:21:40.140147Z",
     "shell.execute_reply.started": "2022-05-22T16:17:08.786746Z"
    },
    "papermill": {
     "duration": 0.027639,
     "end_time": "2022-05-22T16:21:40.140272",
     "exception": false,
     "start_time": "2022-05-22T16:21:40.112633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_melspec(y, params):\n",
    "    \"\"\"\n",
    "    Computes a mel-spectrogram and puts it at decibel scale\n",
    "    Arguments:\n",
    "        y {np array} -- signal\n",
    "        params {AudioParams} -- Parameters to use for the spectrogram. Expected to have the attributes sr, n_mels, f_min, f_max\n",
    "    Returns:\n",
    "        np array -- Mel-spectrogram\n",
    "    \"\"\"\n",
    "    melspec = librosa.feature.melspectrogram(\n",
    "        y=y, sr=params.sr, n_mels=params.n_mels, fmin=params.fmin, fmax=params.fmax,\n",
    "    )\n",
    "\n",
    "    melspec = librosa.power_to_db(melspec).astype(np.float32)\n",
    "    return melspec\n",
    "\n",
    "\n",
    "def mono_to_color(X, eps=1e-6, mean=None, std=None):\n",
    "    \"\"\"\n",
    "    Converts a one channel array to a 3 channel one in [0, 255]\n",
    "    Arguments:\n",
    "        X {numpy array [H x W]} -- 2D array to convert\n",
    "    Keyword Arguments:\n",
    "        eps {float} -- To avoid dividing by 0 (default: {1e-6})\n",
    "        mean {None or np array} -- Mean for normalization (default: {None})\n",
    "        std {None or np array} -- Std for normalization (default: {None})\n",
    "    Returns:\n",
    "        numpy array [3 x H x W] -- RGB numpy array\n",
    "    \"\"\"\n",
    "    X = np.stack([X, X, X], axis=-1)\n",
    "\n",
    "    # Standardize\n",
    "    mean = mean or X.mean()\n",
    "    std = std or X.std()\n",
    "    X = (X - mean) / (std + eps)\n",
    "\n",
    "    # Normalize to [0, 255]\n",
    "    _min, _max = X.min(), X.max()\n",
    "\n",
    "    if (_max - _min) > eps:\n",
    "        V = np.clip(X, _min, _max)\n",
    "        V = 255 * (V - _min) / (_max - _min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        V = np.zeros_like(X, dtype=np.uint8)\n",
    "\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1128f758",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:21:40.182620Z",
     "iopub.status.busy": "2022-05-22T16:21:40.181686Z",
     "iopub.status.idle": "2022-05-22T16:21:40.185684Z",
     "shell.execute_reply": "2022-05-22T16:21:40.185268Z",
     "shell.execute_reply.started": "2022-05-22T16:17:08.797620Z"
    },
    "papermill": {
     "duration": 0.028202,
     "end_time": "2022-05-22T16:21:40.185781",
     "exception": false,
     "start_time": "2022-05-22T16:21:40.157579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(torchdata.Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, clip: np.ndarray):\n",
    "        self.df = df\n",
    "        # self.clip = clip\n",
    "        self.clip = np.concatenate([clip, clip, clip])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        SR = 32000\n",
    "        sample = self.df.loc[idx, :]\n",
    "        row_id = sample.row_id\n",
    "\n",
    "        end_seconds = int(sample.seconds)\n",
    "        start_seconds = int(end_seconds - 5)\n",
    "        \n",
    "        # end_index = int(SR * (end_seconds + (self.train_period - 5) / 2) + len(self.clip) // 3)\n",
    "        # start_index = int(SR * (start_seconds - (self.train_period - 5) / 2) + len(self.clip) // 3)\n",
    "        \n",
    "        # y = self.clip[start_index:end_index].astype(np.float32)\n",
    "        image = self.clip[SR*start_seconds:SR*end_seconds].astype(np.float32)\n",
    "        image = np.nan_to_num(image)\n",
    "        \n",
    "        image = compute_melspec(image, AudioParams)\n",
    "        image = mono_to_color(image)\n",
    "        image = image.astype(np.uint8)\n",
    "\n",
    "        image = albu_transforms['valid'](image=image)['image'].T\n",
    "            \n",
    "        return {\n",
    "            \"image\": image,\n",
    "            \"row_id\": row_id,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0a641aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:21:40.226587Z",
     "iopub.status.busy": "2022-05-22T16:21:40.226009Z",
     "iopub.status.idle": "2022-05-22T16:21:43.832658Z",
     "shell.execute_reply": "2022-05-22T16:21:43.833099Z",
     "shell.execute_reply.started": "2022-05-22T16:17:08.810360Z"
    },
    "papermill": {
     "duration": 3.630443,
     "end_time": "2022-05-22T16:21:43.833260",
     "exception": false,
     "start_time": "2022-05-22T16:21:40.202817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_paths = ['../input/birdclef2022-use-2nd-label-f0/fold-0.bin']\n",
    "\n",
    "models = []\n",
    "for p in model_paths:\n",
    "    model = TimmSED(\n",
    "        base_model_name=CFG.base_model_name,\n",
    "        pretrained=CFG.pretrained,\n",
    "        num_classes=CFG.num_classes,\n",
    "        in_channels=CFG.in_channels)\n",
    "    \n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(p))\n",
    "    model.eval()\n",
    "    models.append(model)\n",
    "    \n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "156dfe94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:21:43.873731Z",
     "iopub.status.busy": "2022-05-22T16:21:43.872219Z",
     "iopub.status.idle": "2022-05-22T16:21:43.874412Z",
     "shell.execute_reply": "2022-05-22T16:21:43.874806Z",
     "shell.execute_reply.started": "2022-05-22T16:17:12.726412Z"
    },
    "papermill": {
     "duration": 0.023977,
     "end_time": "2022-05-22T16:21:43.874931",
     "exception": false,
     "start_time": "2022-05-22T16:21:43.850954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TARGET_SR = 32000\n",
    "DATADIR = Path(\"../input/birdclef-2022/test_soundscapes/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5330d73b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:21:43.914073Z",
     "iopub.status.busy": "2022-05-22T16:21:43.913517Z",
     "iopub.status.idle": "2022-05-22T16:21:43.938549Z",
     "shell.execute_reply": "2022-05-22T16:21:43.938905Z",
     "shell.execute_reply.started": "2022-05-22T16:17:12.733961Z"
    },
    "papermill": {
     "duration": 0.046451,
     "end_time": "2022-05-22T16:21:43.939085",
     "exception": false,
     "start_time": "2022-05-22T16:21:43.892634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soundscape_1000170626_akiapo_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soundscape_1000170626_akiapo_10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soundscape_1000170626_akiapo_15</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            row_id  target\n",
       "0   soundscape_1000170626_akiapo_5   False\n",
       "1  soundscape_1000170626_akiapo_10   False\n",
       "2  soundscape_1000170626_akiapo_15   False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_audios = list(DATADIR.glob(\"*.ogg\"))\n",
    "sample_submission = pd.read_csv('../input/birdclef-2022/sample_submission.csv')\n",
    "sample_submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88ebc0f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:21:43.985869Z",
     "iopub.status.busy": "2022-05-22T16:21:43.982758Z",
     "iopub.status.idle": "2022-05-22T16:21:43.988893Z",
     "shell.execute_reply": "2022-05-22T16:21:43.988489Z",
     "shell.execute_reply.started": "2022-05-22T16:17:12.764196Z"
    },
    "papermill": {
     "duration": 0.031546,
     "end_time": "2022-05-22T16:21:43.989025",
     "exception": false,
     "start_time": "2022-05-22T16:21:43.957479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prediction_for_clip(test_df: pd.DataFrame, \n",
    "                        clip: np.ndarray, \n",
    "                        models, \n",
    "                        threshold=0.05, \n",
    "                        threshold_long=None):\n",
    "\n",
    "    dataset = TestDataset(df=test_df, \n",
    "                          clip=clip,)\n",
    "    loader = torchdata.DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "#     [model.eval() for model in models]\n",
    "    prediction_dict = {}\n",
    "    for data in tqdm(loader):\n",
    "        row_id = data['row_id'][0]\n",
    "        image = data['image'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            probas = []\n",
    "            probas_long = []\n",
    "            for model in models:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    output = model(image)\n",
    "                probas.append(output['clipwise_output'].detach().cpu().numpy().reshape(-1))\n",
    "                # probas_long.append(clipwise_pred_long.detach().cpu().numpy().reshape(-1))\n",
    "            probas = np.array(probas)\n",
    "            # probas_long = np.array(probas_long)\n",
    "#             probas = np.array([model(image)[1].detach().cpu().numpy().reshape(-1) for model in models])\n",
    "        if threshold_long is None:\n",
    "            events = probas.mean(0) >= threshold\n",
    "        else:\n",
    "            events = ((probas.mean(0) >= threshold).astype(int) \\\n",
    "                      + (probas_long.mean(0) >= threshold_long).astype(int)) >= 2\n",
    "        labels = np.argwhere(events).reshape(-1).tolist()\n",
    "#         labels = labels[:2]\n",
    "        if len(labels) == 0:\n",
    "            prediction_dict[str(row_id)] = \"nocall\"\n",
    "        else:\n",
    "            labels_str_list = list(map(lambda x: CFG.target_columns[x], labels))\n",
    "            label_string = \" \".join(labels_str_list)\n",
    "            prediction_dict[str(row_id)] = label_string\n",
    "    return prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba7f8a3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:21:44.033106Z",
     "iopub.status.busy": "2022-05-22T16:21:44.032292Z",
     "iopub.status.idle": "2022-05-22T16:21:44.034752Z",
     "shell.execute_reply": "2022-05-22T16:21:44.034327Z",
     "shell.execute_reply.started": "2022-05-22T16:17:12.777822Z"
    },
    "papermill": {
     "duration": 0.028044,
     "end_time": "2022-05-22T16:21:44.034849",
     "exception": false,
     "start_time": "2022-05-22T16:21:44.006805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prediction(test_audios,\n",
    "               threshold=0.05, \n",
    "               threshold_long=None):\n",
    "    \n",
    "    # models = [model]\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    prediction_dicts = {}\n",
    "    for audio_path in test_audios:\n",
    "        with timer(f\"Loading {str(audio_path)}\", logger):\n",
    "            clip, _ = sf.read(audio_path, always_2d=True)\n",
    "            clip = np.mean(clip, 1)\n",
    "            \n",
    "        seconds = []\n",
    "        row_ids = []\n",
    "        for second in range(5, 65, 5):\n",
    "            row_id = \"_\".join(audio_path.name.split(\".\")[:-1]) + f\"_{second}\"\n",
    "            seconds.append(second)\n",
    "            row_ids.append(row_id)\n",
    "        print(row_ids)\n",
    "        test_df = pd.DataFrame({\n",
    "            \"row_id\": row_ids,\n",
    "            \"seconds\": seconds\n",
    "        })\n",
    "        with timer(f\"Prediction on {audio_path}\", logger):\n",
    "            prediction_dict = prediction_for_clip(test_df,\n",
    "                                                  clip=clip,\n",
    "                                                  models=models,\n",
    "                                                  threshold=threshold, threshold_long=threshold_long)\n",
    "#         row_id = list(prediction_dict.keys())\n",
    "#         birds = list(prediction_dict.values())\n",
    "#         prediction_df = pd.DataFrame({\n",
    "#             \"row_id\": row_id,\n",
    "#             \"birds\": birds\n",
    "#         })\n",
    "#         prediction_dfs.append(prediction_df)\n",
    "#     prediction_df = pd.concat(prediction_dfs, axis=0, sort=False).reset_index(drop=True)\n",
    "        prediction_dicts.update(prediction_dict)\n",
    "    return prediction_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8539006e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:21:44.076400Z",
     "iopub.status.busy": "2022-05-22T16:21:44.075844Z",
     "iopub.status.idle": "2022-05-22T16:21:50.845884Z",
     "shell.execute_reply": "2022-05-22T16:21:50.846648Z",
     "shell.execute_reply.started": "2022-05-22T16:17:12.789742Z"
    },
    "papermill": {
     "duration": 6.794532,
     "end_time": "2022-05-22T16:21:50.846911",
     "exception": false,
     "start_time": "2022-05-22T16:21:44.052379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-22 16:21:44,074 - INFO - [Loading ../input/birdclef-2022/test_soundscapes/soundscape_453028782.ogg] start\n",
      "2022-05-22 16:21:44,146 - INFO - [Loading ../input/birdclef-2022/test_soundscapes/soundscape_453028782.ogg] done in 0.07 s\n",
      "2022-05-22 16:21:44,148 - INFO - [Prediction on ../input/birdclef-2022/test_soundscapes/soundscape_453028782.ogg] start\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['soundscape_453028782_5', 'soundscape_453028782_10', 'soundscape_453028782_15', 'soundscape_453028782_20', 'soundscape_453028782_25', 'soundscape_453028782_30', 'soundscape_453028782_35', 'soundscape_453028782_40', 'soundscape_453028782_45', 'soundscape_453028782_50', 'soundscape_453028782_55', 'soundscape_453028782_60']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:06<00:00,  1.80it/s]\n",
      "2022-05-22 16:21:50,829 - INFO - [Prediction on ../input/birdclef-2022/test_soundscapes/soundscape_453028782.ogg] done in 6.68 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'soundscape_453028782_5': 'amewig arcter bcnher bkbplo brant brnowl calqua cangoo caster1 categr chukar commyn comsan dunlin eurwig gadwal gamqua gnwtea gresca gwfgoo hawpet1 jabwar japqua magpet1 mallar3 moudov norpin norsho osprey pagplo pecsan perfal redjun refboo rinphe rocpig rudtur ruff sander sheowl skylar wetshe whiter whttro wiltur', 'soundscape_453028782_10': 'amewig arcter bcnher bkbplo bongul brant brnowl calqua cangoo caster1 categr chukar commyn comsan comwax dunlin eurwig gadwal gamqua gnwtea gresca gwfgoo hawpet1 houfin houspa jabwar japqua magpet1 mallar3 merlin moudov norpin norsho osprey pagplo pecsan perfal redjun refboo rinphe rocpig rorpar rudtur ruff sander sheowl skylar sposan wantat1 warwhe1 wesmea wetshe whiter whttro wiltur', 'soundscape_453028782_15': 'amewig arcter barpet bcnher belkin1 bkbplo bongul brant brnboo brnnod brnowl buffle calqua cangoo canvas caster1 categr chukar commyn comsan dunlin eurwig gadwal gamqua glwgul gnwtea gresca gwfgoo hawpet1 hoomer houspa incter1 jabwar japqua kalphe lessca magpet1 mallar3 merlin moudov norpin norsho osprey pagplo pecsan perfal redjun refboo ribgul rinduc rinphe rocpig rorpar rudtur ruff sander sheowl skylar sooshe sora sposan wantat1 warwhe1 wesmea wetshe whiter whttro wiltur zebdov', 'soundscape_453028782_20': 'amewig arcter bcnher bkbplo brant brnowl cangoo caster1 categr chukar commyn comsan dunlin eurwig gadwal gnwtea gresca gwfgoo hawpet1 jabwar japqua magpet1 mallar3 norpin norsho osprey pecsan perfal redjun refboo rinphe rocpig rudtur ruff sander sheowl skylar warwhe1 wetshe whiter whttro wiltur', 'soundscape_453028782_25': 'amewig arcter bcnher belkin1 bkbplo brant brnboo brnowl buffle calqua cangoo caster1 categr chukar commyn comsan comwax dunlin eurwig gadwal gamqua gnwtea gresca gwfgoo hawpet1 houspa incter1 jabwar japqua magpet1 mallar3 merlin moudov norpin norsho osprey pecsan perfal refboo rinphe rocpig rorpar rudtur ruff sander sheowl skylar sposan wantat1 warwhe1 wetshe whiter whttro wiltur', 'soundscape_453028782_30': 'amewig arcter bcnher bkbplo brant brnowl calqua cangoo caster1 categr chukar commyn comsan comwax dunlin eurwig gadwal gamqua gnwtea gresca gwfgoo hawpet1 hoomer jabwar japqua kalphe magpet1 mallar3 moudov norcar norpin norsho osprey pagplo pecsan perfal redjun refboo rinphe rocpig rorpar rudtur ruff sander sheowl skylar sposan warwhe1 wetshe whiter wiltur', 'soundscape_453028782_35': 'amewig arcter bcnher bkbplo bongul brant buwtea calqua cangoo canvas caster1 categr chbsan chukar commyn comsan dunlin eurwig fragul gadwal gamqua gnwtea gresca gwfgoo hawpet1 jabwar kalphe mallar3 norpin norsho osprey pagplo pecsan perfal rinduc rinphe rocpig rudtur ruff sander sheowl skylar whiter wiltur', 'soundscape_453028782_40': 'amewig arcter barpet bcnher belkin1 bkbplo blknod bongul brant brnnod brnowl buffle calqua cangoo caster1 categr chukar commyn comsan comwax dunlin eurwig gadwal gamqua gnwtea gresca gwfgoo hawpet1 hoomer houfin houspa incter1 jabwar japqua kalphe magpet1 mallar3 merlin moudov norcar norpin norsho osprey pagplo pecsan perfal redjun refboo ribgul rinphe rocpig rorpar rudtur ruff sander sheowl skylar sooshe sora sposan towsol wantat1 warwhe1 wesmea wetshe whiter whttro wiltur zebdov', 'soundscape_453028782_45': 'amewig aniani apapan arcter bcnher belkin1 bkbplo brant buwtea calqua cangoo caster1 categr chukar commyn comsan comwax dunlin eurwig gadwal gamqua gnwtea gresca gwfgoo hawama hawpet1 houspa iiwi incter1 jabwar japqua kalphe mallar3 moudov norpin norsho osprey pagplo pecsan perfal redava redjun refboo ribgul rinduc rinphe rocpig rudtur ruff sander sheowl skylar sooshe sposan towsol wantat1 warwhe1 wesmea wetshe whiter whttro wiltur', 'soundscape_453028782_50': 'amewig arcter bcnher belkin1 bkbplo bongul brant brnowl calqua cangoo caster1 categr chukar commyn comsan dunlin eurwig gadwal gamqua gnwtea gresca gwfgoo hawpet1 hoomer houspa incter1 jabwar japqua kalphe magpet1 mallar3 merlin moudov norpin norsho osprey pagplo pecsan perfal redjun refboo rinphe rocpig rudtur ruff sander sheowl skylar sora sposan wantat1 warwhe1 wesmea wetshe whiter whttro wiltur', 'soundscape_453028782_55': 'amewig arcter barpet bcnher belkin1 bkbplo brant brnnod brnowl buffle calqua cangoo caster1 categr chukar commyn comsan dunlin eurwig gadwal gamqua gnwtea gresca gwfgoo hawpet1 hoomer houspa incter1 jabwar japqua kalphe magpet1 mallar3 merlin moudov norpin norsho osprey pagplo pecsan perfal redjun refboo rinphe rocpig rorpar rudtur ruff sander sheowl skylar sooshe sposan wantat1 warwhe1 wetshe whiter whttro wiltur', 'soundscape_453028782_60': 'amewig bcnher bkbplo bongul brant brnowl buwtea calqua cangoo caster1 categr chbsan chukar commyn comsan dunlin eurwig gadwal gnwtea gresca hawpet1 houfin japqua mallar3 moudov norpin norsho osprey pecsan rinduc rinphe rocpig rudtur ruff sander sheowl skylar wesmea whttro wiltur'}\n",
      "soundscape_1000170626_5 akiapo\n",
      "soundscape_1000170626_10 akiapo\n",
      "soundscape_1000170626_15 akiapo\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.05\n",
    "threshold_long = None # 0.05\n",
    "\n",
    "prediction_dicts = prediction(test_audios=all_audios,\n",
    "           threshold=threshold, \n",
    "           threshold_long=threshold_long)\n",
    "print(prediction_dicts)\n",
    "\n",
    "for i in range(len(sample_submission)):\n",
    "    sample = sample_submission.row_id[i]\n",
    "    key = sample.split(\"_\")[0] + \"_\" + sample.split(\"_\")[1] + \"_\" + sample.split(\"_\")[3]\n",
    "    target_bird = sample.split(\"_\")[2]\n",
    "    print(key, target_bird)\n",
    "    if key in prediction_dicts:\n",
    "        sample_submission.iat[i, 1] = (target_bird in prediction_dicts[key])\n",
    "sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22358efe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-22T16:21:50.941752Z",
     "iopub.status.busy": "2022-05-22T16:21:50.940900Z",
     "iopub.status.idle": "2022-05-22T16:21:50.944950Z",
     "shell.execute_reply": "2022-05-22T16:21:50.945527Z",
     "shell.execute_reply.started": "2022-05-22T16:17:19.622394Z"
    },
    "papermill": {
     "duration": 0.055757,
     "end_time": "2022-05-22T16:21:50.945701",
     "exception": false,
     "start_time": "2022-05-22T16:21:50.889944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soundscape_1000170626_akiapo_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soundscape_1000170626_akiapo_10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soundscape_1000170626_akiapo_15</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            row_id  target\n",
       "0   soundscape_1000170626_akiapo_5   False\n",
       "1  soundscape_1000170626_akiapo_10   False\n",
       "2  soundscape_1000170626_akiapo_15   False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a813eef",
   "metadata": {
    "papermill": {
     "duration": 0.025747,
     "end_time": "2022-05-22T16:21:50.996763",
     "exception": false,
     "start_time": "2022-05-22T16:21:50.971016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7c548c",
   "metadata": {
    "papermill": {
     "duration": 0.022743,
     "end_time": "2022-05-22T16:21:51.042322",
     "exception": false,
     "start_time": "2022-05-22T16:21:51.019579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 55.974808,
   "end_time": "2022-05-22T16:21:52.678735",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-22T16:20:56.703927",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
